#! https://zhuanlan.zhihu.com/p/553574337
- [12.PyTorch中进行卷积残差模块算子融合](#12pytorch中进行卷积残差模块算子融合)
  - [Convolution Layers](#convolution-layers)
    - [`torch.nn.Conv2d`](#torchnnconv2d)
  - [卷积残差模块算子融合](#卷积残差模块算子融合)

# 12.PyTorch中进行卷积残差模块算子融合

首先安利一篇Dropout的文章：[arxiv链接](https://arxiv.org/pdf/2106.14448.pdf)

*R-Drop: Regularized Dropout for Neural Networks*

解决训练和测试dropout不一致的问题,感兴趣的同学可以看看。（嗯我太懒了）

接下来继续讲torch.nn里面的内容

## Convolution Layers

### [`torch.nn.Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d)

```python
torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, 
dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
'''
padding:`valid`不做padding,`same`pad到最后一个像素点,步长=1时，输出与输入尺寸一致

dilation:空洞卷积，大于1时增大卷积范围

groups:把通道分成多组，默认groups=1,深度可分离卷积就是把groups设置成大于1的一个数
它必须被in_channels和out_channels整除
groups>1时计算量有下降

'''
```

同理，和dropout一样，卷积在`torch.nn.functional.conv2d`中也有一个函数
```python
torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, 
dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
```

```python
import torch
conv_layer = torch.nn.Conv2d(2, 4, 3, padding="same")

for i in conv_layer.named_parameters():
    print(i)

conv_layer.weight.size() #torch.Size([4, 2, 3, 3]) 输出通道*输入通道*卷积核大小

conv_layer.bias.size() #torch.Size([4,]) 和输出通道相关

```

point-wise convolution:1*1卷积,不考虑局部关联性，只对每个通道上加权求和，相当于一个MLP

depth-wise convolution:groups > 1，并没有把所有通道混合，减少了计算量
```python
'''
把卷积分成两部分，每部分输入通道为1，输出通道为2，最后再拼起来
'''
conv_layer = torch.nn.Conv2d(2, 4, 3, padding="same", groups = 2)

conv_layer.weight.size() #torch.Size([4, 1, 3, 3]) 输出通道*输入通道*卷积核大小

conv_layer.bias.size() #torch.Size([4,]) 和输出通道相关

'''
以上过程等价于下面的形式
'''
conv_layer1 = torch.nn.Conv2d(1, 2, 3, padding = 'same')
conv_layer2 = torch.nn.Conv2d(1, 2, 3, padding = 'same')
conv_layer.weight.size() #[2,1,3,3]
conv_layer.bias.size() #[2]
#拼起来就是[4,1,3,3]和[4]就是上面的groups = 2的情况了
```

## 卷积残差模块算子融合
有了以上知识储备，我们就可以看一下**卷积残差模块算子融合**

源自论文**RepVGG: Making VGG-style ConvNets Great Again**

如图所示，左上第一个残差块中有3x3, 1x1还有输入input本身，但是实际上我们可以统一成下方
都用3x3卷积来做，这就是算子融合。

![卷积残差模块算子融合](https://pic4.zhimg.com/80/v2-c15e02b93d91b3ceaff744bc8e0e6229.png)

```python
import time
import torch
import torch.nn.functional as F
import torch.nn as nn
#conv_block_fusion

in_channels = 2
out_channels = 2
kernel_size = 3
w = 9
h = 9
x = torch.ones(1, in_channels, w, h )  #输入图片batch_size * channels * w * h 简称NCHW

#res_block = 3*3 conv + 1*1 conv + input

#方法一：原生写法 
conv_2d = nn.Conv2d(in_channels, out_channels, kernel_size, padding = "same")
conv_2d_pointwise = nn.Conv2d(in_channels, out_channels, 1)
result1 = conv_2d(x) + conv_2d_pointwise(x) + x

#方法二：算子融合
#把point-wise卷积和x本身都写成3*3的卷积，最终把三个卷积写成一个卷积
#conv_2d_pointwise.weight[2,2,1,1] pad 成p[2, 2, 3, 3]
#pad从内向外，每次前后两个方向
#1.改造
pointwise_to_conv_weight = F.pad(conv_2d_pointwise.weight, [1,1,1,1,0,0,0,0])
conv_2d_for_pointwise = nn.Conv2d(in_channels, out_channels, kernel_size, padding="same")
#注意参数用Parameter包装
conv_2d_for_pointwise.weight = nn.Parameter(pointwise_to_conv_weight)
conv_2d_for_pointwise.bias = conv_2d_for_pointwise.bias

'''
把x本身编成3x3卷积
#1.首先要是point-wise卷积（不考虑相邻点关联性）
#2.只要考虑第一个通道，不考虑其他通道（不考虑通道关联性）

对于2x2x3x3的卷积核，可以想象，就是4个3x3的卷积核，每个3x3卷积至少都是中间为1，周围是0
由于只考虑第一个通道，第一个3x3就是如上面所述的point-wise矩阵
第二个3x3就是全0矩阵，第三个也是全0，第四个是point-wise矩阵（输出第二通道只考虑输入第二通道）
'''
zeros = torch.unsqueeze(torch.zeros(kernel_size, kernel_size), 0) #1*3*3
stars = torch.unsqueeze(F.pad(torch.ones(1,1),[1,1,1,1]),0) #1*3*3
starts_zeros = torch.unsqueeze(torch.cat([stars, zeros],0),0) #第一个输出通道
zeros_starts = torch.unsqueeze(torch.cat([zeros,stars],0),0) #第二个输出通道
identity_to_conv_weight = torch.cat([stars_zeros, zeros_stars], 0)
identity_to_conv_bias = torch.zeros([out_channels])

#实例化一个”假的“3x3卷积
conv_2d_for_identity = nn.Conv2d(in_channels, out_channels, kernel_size, padding="same")

conv_2d_for_identity.weight = nn.Parameter(identity_to_conv_weight)
conv_2d_for_identity.bias = nn.Parameter(identity_to_conv_bias)

result2 = conv2d(x) + conv_2d_for_pointwise(x) + conv_2d_for_identity(x)

print(torch.all(torch.isclose(result1,result2)))#由于是一个张量，加一个all，看每个位置是否都相等

#2.融合，把三个卷积变成一个卷积
t1 = time.time()

conv_2d_for_fusion = nn.Conv2d(in_channels, out_channels, kernel_size, padding="same")
#对weight和bias进行修改
conv_2d_for_fusion.weight = nn.Parameter(conv_2d.weight.data + conv_2d_for_pointwise.
weight + conv_2d_for_identity.weight)

conv_2d_for_fusion.bias = nn.Parameter(conv_2d.weight.bias + conv_2d_for_pointwise.
bias + conv_2d_for_identity.bias)

result3 = conv_2d_for_fusion(x) #一个卷积算子实现三个卷积过程
print(torch.all(torch.isclose(result3,result2)))
t2 = time.time()
#进行时间对比
t3 = time.time()
conv_2d = nn.Conv2d(in_channels, out_channels, kernel_size, padding = "same")
conv_2d_pointwise = nn.Conv2d(in_channels, out_channels, 1)
result1 = conv_2d(x) + conv_2d_pointwise(x) + x
t4 = time.time()

print("原生写法耗时：",t4-t3) #0.0004

print("算子融合写法耗时：",t2-t1) #0.0002~0.0003

#使用python优化，都可以做到这种优化程度，底层C++的优化更明显
```