#! https://zhuanlan.zhihu.com/p/555387428
# 20.手写实现空洞卷积与群卷积
```python
# 空洞卷积

import torch
import torch.nn as nn
import torch.nn.functional as F
a = torch.randn(7,7)
a

a[0:3, 0:3] #如果和3x3卷积核
a[0:3, 0:3] #dilation = 1
a[0:5:2, 0:5:2] #dilation = 2 在不增加计算量的情况下，增加感受野的面积
a[0:7:3, 0:7:3] #dilation = 3


#group > 1，把一个大卷积看出多个小卷积，通道融合不需要完全充分，只在group内融合
#后面加一个1*1 pointwise convolution即可，就是前面说的convmixer的方法
in_channel, out_channel = 2, 4
group = 2
sub_in_channel, sub_out_channel = 1, 2 #2组一共4个卷积核，相比上面8个卷积核少了一半，没有考虑通道融合

```


最终带空洞和group的卷积实现
```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import math
def matrix_multiplication_for_conv2d_final(input, kernel, bias = None, stride = 1, padding = 0, dilation = 1, groups = 1):
    if padding > 0:
        input = F.pad(input, (padding,padding,padding,padding,0,0,0,0))
    bs, in_channel, input_h, input_w = input.shape    
    out_channel,_, kernel_h, kernel_w = kernel.shape

    assert out_channel % groups == 0 and in_channel % groups == 0,"groups必须要同时被通道数整除！"
    input = input.reshape((bs, groups,in_channel//groups,input_h, input_w))

    kernel = kernel.reshape((groups, out_channel//groups, in_channel//groups, kernel_h, kernel_w))
    
    kernel_h = (kernel_h-1) *(dilation-1) + kernel_h#后面是卷积作用的点，前面是空洞的数目，加起来就是作用范围
    kernel_w = (kernel_w-1) *(dilation-1) + kernel_w

    output_h = math.floor((input_h-kernel_h)/stride)+1
    output_w = math.floor((input_w-kernel_w)/stride)+1
    output_shape = (bs, groups, out_channel//groups, output_h, output_w)
    output = torch.zeros(output_shape)

    if bias is None:
        bias = torch.zeros(out_channel)

    for ind in range(bs): #对batch_size进行遍历
        for g in range(groups): #对群组进行遍历
            for oc in range(out_channel//groups): #对分组后的通道进行遍历
                for ic in range(in_channel//groups): #对分组后的输入通道进行遍历
                    for i in range(0, input_h-kernel_h+1, stride):
                        for j in range(0, input_w-kernel_w+1, stride):
                            region = input[ind, g, ic, i:i+kernel_h:dilation,j:j+kernel_w:dilation] #特征区域
                            output[ind, g, oc, int(i/stride), int(j/stride)] += torch.sum(region * kernel[g, oc, ic])
                output[ind, g, oc] += bias[g*(out_channel//groups)+oc ]#考虑偏置
    
    output = output.reshape((bs,out_channel, output_h,output_w))#还原成4维
    return output

#开始验证测试
kernel_size = 3
bs, in_channel, input_h, input_w = 2, 2, 5, 5
out_channel = 4
groups ,dilation, stride, padding= 2 ,2 ,2, 1
input = torch.randn(bs,in_channel,input_h,input_w)
kernel = torch.randn(out_channel,in_channel//groups,kernel_size, kernel_size )
bias = torch.randn(out_channel)

pytorch_conv2d_api_output = \
    F.conv2d(input, kernel, bias=bias,padding=padding,stride=stride,dilation=dilation,groups=groups)

mm_conv2d_final_output = matrix_multiplication_for_conv2d_final\
    (input, kernel, bias = bias, stride = stride, padding = padding, dilation = dilation, groups = groups)

flag = torch.allclose(pytorch_conv2d_api_output, mm_conv2d_final_output)
flag
```