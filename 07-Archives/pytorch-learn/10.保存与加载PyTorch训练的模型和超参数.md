#! https://zhuanlan.zhihu.com/p/553477478
- [10.保存与加载PyTorch训练的模型和超参数](#10保存与加载pytorch训练的模型和超参数)
  - [加载或保存模型用于推理](#加载或保存模型用于推理)
  - [在pytorch中加载或保存一个通用的checkpoint](#在pytorch中加载或保存一个通用的checkpoint)
  - [使用Pytorch在一个文件中保存或加载多个模型](#使用pytorch在一个文件中保存或加载多个模型)
  - [机器学习流程初探](#机器学习流程初探)

# 10.保存与加载PyTorch训练的模型和超参数

本节对应[官网链接](https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_models_for_inference.html)

本节主要讲三块内容：
- [加载或保存模型用于推理](https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_models_for_inference.html)
- [在pytorch中加载或保存一个通用的checkpoint](https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html)
- [使用Pytorch在一个文件中保存或加载多个模型](https://pytorch.org/tutorials/recipes/recipes/saving_multiple_models_in_one_file.html)

## 加载或保存模型用于推理
pytorch中有两种方法保存和加载模型：
1. 保存或加载`state_dict`
2. 保存或加载整个model

`state_dict`在`Module`类的源码中，位置在torch/nn/modules/module.py源码中

1. 定义一个网络
```python
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

net = Net()
print(net)
```

2. 初始化优化器
```python
#传入parameters()函数才能对子module也遍历
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
```

3. 通过`state_dict`保存模型

pytorch一般用`.pt`或者`.pth`作为扩展名保存`state_dict`，自己起名称时可以加上loss\epoch等信息

tensorflow保存checkpoint一般用`.ckpt`扩展名

注意`state_dict`没有保存网络架构，需要自己实例化
前面说过优化器也有参数，也可以保存`state_dict`，下面是做inference就不保存了
```python
# Specify a path
PATH = "state_dict_model.pt"

# Save
torch.save(net.state_dict(), PATH)

# Load
model = Net() #要先实例化模型
model.load_state_dict(torch.load(PATH))
model.eval()
```

4. 保存或者加载整个model

```python
# Specify a path
PATH = "entire_model.pt"

# Save
torch.save(net, PATH)

# Load
model = torch.load(PATH)#可以不实例化模型
model.eval()
```

## 在pytorch中加载或保存一个通用的checkpoint
加载或保存一个通用的checkpoint有两个用处
- 当然用来做推理
- 用来继续训练模型
保存和加载通用检查点模型以进行推理或恢复训练可能有助于从上次中断的地方开始。保存常规检查点时，必须保存的不仅仅是模型的 state_dict。保存优化器的 state_dict 也很重要，因为它包含随着模型训练而更新的缓冲区和参数。

**训练的时候最好用这种方法保存**

1. 定义一个网络
2. 初始化优化器
3. 保存checkpoint

```python
# Additional information
EPOCH = 5
PATH = "model.pt"
LOSS = 0.4
#保存一个dict
torch.save({
            'epoch': EPOCH,
            'model_state_dict': net.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss': LOSS,
            }, PATH)
```

4. 加载checkpoint

```python
model = Net()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

checkpoint = torch.load(PATH)
model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']
loss = checkpoint['loss']

model.eval()
# - or -
model.train()
```

## 使用Pytorch在一个文件中保存或加载多个模型

1. 定义一个网络
2. 初始化优化器
3. 保存多个模型

```python
# Specify a path to save to
PATH = "model.pt"

torch.save({
            'modelA_state_dict': netA.state_dict(),
            'modelB_state_dict': netB.state_dict(),
            'optimizerA_state_dict': optimizerA.state_dict(),
            'optimizerB_state_dict': optimizerB.state_dict(),
            }, PATH)
```

4. 加载多个模型

```python
modelA = Net()
modelB = Net()
optimModelA = optim.SGD(modelA.parameters(), lr=0.001, momentum=0.9)
optimModelB = optim.SGD(modelB.parameters(), lr=0.001, momentum=0.9)

checkpoint = torch.load(PATH)
modelA.load_state_dict(checkpoint['modelA_state_dict'])
modelB.load_state_dict(checkpoint['modelB_state_dict'])
optimizerA.load_state_dict(checkpoint['optimizerA_state_dict'])
optimizerB.load_state_dict(checkpoint['optimizerB_state_dict'])

modelA.eval()
modelB.eval()
# - or -
modelA.train()
modelB.train()
```

## 机器学习流程初探

一句话：**用好Docker**

![机器学习流程](https://pic4.zhimg.com/80/v2-23972b61f323455be99c51efa041ff2a.png)

![常用库](https://pic4.zhimg.com/80/v2-611e44b365f725bac406914e7c5fbd90.png)