#! https://zhuanlan.zhihu.com/p/556339822
# 29.基于PyTorch ResNet18的果蔬分类逐行代码讲解

果蔬图像分类数据集来源：
https://aistudio.baidu.com/aistudio/datasetdetail/119023/0
https://www.kaggle.com/datasets/kritikseth/fruit-and-vegetable-image-recognition

该数据集包含以下食品的图像：

水果 - 香蕉、苹果、梨、葡萄、橙子、猕猴桃、西瓜、石榴、菠萝、芒果。
蔬菜 - 黄瓜、胡萝卜、辣椒、洋葱、马铃薯、柠檬、番茄、萝卜、甜菜根、卷心菜、生菜、菠菜、大豆、花椰菜、甜椒、辣椒、萝卜、玉米、甜玉米、红薯、辣椒粉、生姜、大蒜、豌豆、茄子。
该数据集包含三个文件夹：

训练（每个 100 张图像）
测试（每个 10 张图像）
验证（每张 10 张图片）
上述每个文件夹都包含不同水果和蔬菜的子文件夹，其中存在相应食品的图像

这里面只能下载训练集，我们手动划分训练集和测试集

这个数据集文件后缀不一致，每张图大小也不一样，所以我们要做两处预处理：
1. 图片全部转化成RGB通道
2. 图片转化成128x128 或者 512x512

首先我们对所有图片进行RGB转化，并且统一调整到一致大小，但不让图片发生变形或扭曲，划分了训练集和测试集

```python
import os
import glob
import random
import shutil
from PIL import Image
""" 对所有图片进行RGB转化，并且统一调整到一致大小，但不让图片发生变形或扭曲，划分了训练集和测试集 """

if __name__ == '__main__':
    test_split_ratio = 0.05 #百分之五的比例作为测试集
    desired_size = 128 # 图片缩放后的统一大小
    raw_path = './raw'

    #把多少个类别算出来，包括目录也包括文件
    dirs = glob.glob(os.path.join(raw_path, '*'))
    #进行过滤，只保留目录，一共36个类别
    dirs = [d for d in dirs if os.path.isdir(d)]

    print(f'Totally {len(dirs)} classes: {dirs}')

    for path in dirs:
        # 对每个类别单独处理

        #只保留类别名称
        path = path.split('/')[-1]

        #创建文件夹
        os.makedirs(f'train/{path}', exist_ok=True)
        os.makedirs(f'test/{path}', exist_ok=True)

        #原始文件夹当前类别的图片进行匹配
        files = glob.glob(os.path.join(raw_path, path, '*.jpg'))
        files += glob.glob(os.path.join(raw_path, path, '*.JPG'))
        files += glob.glob(os.path.join(raw_path, path, '*.png'))

        random.shuffle(files)#原地shuffle，因为要取出来验证集

        boundary = int(len(files)*test_split_ratio) # 训练集和测试集的边界

        for i, file in enumerate(files):
            img = Image.open(file).convert('RGB')

            old_size = img.size  # old_size[0] is in (width, height) format

            ratio = float(desired_size)/max(old_size)

            new_size = tuple([int(x*ratio) for x in old_size])#等比例缩放

            im = img.resize(new_size, Image.ANTIALIAS)#后面的方法不会造成模糊

            new_im = Image.new("RGB", (desired_size, desired_size))

            #new_im在某个尺寸上更大，我们将旧图片贴到上面
            new_im.paste(im, ((desired_size-new_size[0])//2,
                                (desired_size-new_size[1])//2))

            assert new_im.mode == 'RGB'

            if i <= boundary:
                new_im.save(os.path.join(f'test/{path}', file.split('/')[-1].split('.')[0]+'.jpg'))
            else:
                new_im.save(os.path.join(f'train/{path}', file.split('/')[-1].split('.')[0]+'.jpg'))

    test_files = glob.glob(os.path.join('test', '*', '*.jpg'))
    train_files = glob.glob(os.path.join('train', '*', '*.jpg'))

    '''
    Totally 3327 files for training
    Totally 186 files for test
    '''
    print(f'Totally {len(train_files)} files for training')
    print(f'Totally {len(test_files)} files for test')


```
然后，统计数据库中所有图片的每个通道的均值和标准差，虽然我们这次没有对图片通道进行归一化，
但是这个操作很常见，在convnxt或者mae中都对图片进行归一化了
```python
import os
import glob
import random
import shutil
import numpy as np
from PIL import Image
""" 统计数据库中所有图片的每个通道的均值和标准差 

Totally 3327 files for training
(3327, 128, 128, 3)
[0.47298918 0.43487422 0.32614972]
[0.37761145 0.36143682 0.34962901]
"""

if __name__ == '__main__':

    train_files = glob.glob(os.path.join('train', '*', '*.jpg'))

    print(f'Totally {len(train_files)} files for training')
    result = []
    for file in train_files:
        img = Image.open(file).convert('RGB')
        img = np.array(img).astype(np.uint8) #0~255之间
        img = img/255.  #0~1之间，一般很少用0~255的整形放入网络中，除非做像素点的分类任务
        result.append(img)

    print(np.shape(result)) #[BS,H,W,C]
    mean = np.mean(result, axis=(0,1,2))
    std = np.std(result, axis=(0,1,2))
    print(mean)
    print(std)


```
接下来就开始构建分类网络了，有一部分代码 `utils`等借鉴了MAE的代码，直接搬运过来即可，我们这里只说`train.py`的训练代码

训练19个epoch结果

```python
'''
Epoch 19
lengrh of data_loader_train is 46
Evaluating...
Test: [0/3] eta: 0:00:00 loss: 1.1866 (1.1866) acc1: 63.8889 (63.8889) acc5: 93.0556 (93.0556) time: 0.2032 data: 0.1899 max mem: 730
Test: [2/3] eta: 0:00:00 loss: 1.1866 (1.1504) acc1: 63.8889 (64.5161) acc5: 93.0556 (93.5484) time: 0.0748 data: 0.0634 max mem: 730
Test: Total time: 0:00:00 (0.0872 s / it)
* Acc@1 64.516 Acc@5 93.548 loss 1.150
Accuracy of the network on the 186 test images: 64.5%
'''
```
做推理的话，就需要在resume中写入保存的checkpoint路径，同时在main函数里面构建模型
model的pretrained设置成False,把最后的Infer设置成infer

测试日志:

```python
'''
infer model...
number of params (M):11.19
Resume checkpoint /home/hfutzny/sda/output_dir_pretrained/checkpoint-19.pth
With optim & sched!
image path isdataset_fruit_veg/test/mango/Image_96.jpg
score is 0.3039706349372864, class id is19, class name is mango
'''
```


![训练Loss](https://pic4.zhimg.com/80/v2-9f667b244349270e7fe13ce30cff7616.png)

```python
import math
import os
import math
import random
import argparse
from time import time
import glob
import sys
from pathlib import Path
from typing import Iterable, Optional

import numpy as np
import torch
import torch.multiprocessing
torch.multiprocessing.set_sharing_strategy('file_system')
import torch.nn as nn
import torchvision
from torch.utils.tensorboard import SummaryWriter

from PIL import Image
import timm
from timm.utils import accuracy

from util import misc
from util.misc import NativeScalerWithGradNormCount as NativeScaler

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

@torch.no_grad()
def evaluate(data_loader, model, device):
    criterion = torch.nn.CrossEntropyLoss()

    metric_logger = misc.MetricLogger(delimiter=" ")
    header = 'Test:'
    model = model.to(device)
    # switch to evaluation mode
    model.eval()
   
    for batch in metric_logger.log_every(data_loader, 10, header):
        images = batch[0]
        target = batch[-1]
        images = images.to(device, non_blocking = True)
        target = target.to(device, non_blocking = True)

        #compute output

        output = model(images)
        loss = criterion(output, target)

        output = torch.nn.functional.softmax(output, dim = -1)
        acc1, acc5 = accuracy(output, target, topk = (1, 5))
        
        batch_size = images.shape[0]
        metric_logger.update(loss = loss.item())
        metric_logger.meters['acc1'].update(acc1.item(), n = batch_size)
        metric_logger.meters['acc5'].update(acc5.item(), n = batch_size)

    #gather the stats from all processes
    metric_logger.synchronize_between_processes()
    print('* Acc@1 {top1.global_avg:.3f} Acc@5 {top5.global_avg:.3f} loss {losses.global_avg:.3f}'\
        .format(top1 = metric_logger.acc1, top5 = metric_logger.acc5, losses = metric_logger.loss))
    
    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}


def train_one_epoch(model: torch.nn.Module, criterion: torch.nn.Module,\
    data_loader: Iterable, optimizer: torch.optim.Optimizer, device:torch.device,\
        epoch:int, loss_scaler, max_norm: float = 0, log_writer = None, args = None):
    model.train(True)

    print_freq = 2

    accum_iter = args.accum_iter #每隔几步梯度更新，一般是1

    if log_writer is not None:
        print('log_dir:{}'.format(log_writer.log_dir))

    for data_iter_step, (samples, targets) in enumerate(data_loader):
        samples = samples.to(device, non_blocking = True) #移入指定的设备，必不可少
        targets = targets.to(device, non_blocking = True)

        outputs = model(samples)

        #warmup_lr = args.lr*(min(1.0, epoch/2.))
        warmup_lr = args.lr
        optimizer.param_groups[0]["lr"] = warmup_lr #这里其实没用warm_up

        loss = criterion(outputs, targets)
        loss /= accum_iter

        #进行梯度更新
        loss_scaler(loss, optimizer, clip_grad = max_norm, parameters = \
            model.parameters(), create_graph = False, update_grad = (data_iter_step + 1) \
                % accum_iter == 0)
        
        loss_value = loss.item()

        if (data_iter_step + 1 ) % accum_iter == 0:
            optimizer.zero_grad()
        
        if not math.isfinite(loss_value):
            print("Loss is {}, stopping training".format(loss_value))
            sys.exit(1)

            #写入tensorboard
        if log_writer is not None and (data_iter_step + 1) % accum_iter == 0:
            epoch_1000x = int((data_iter_step / len(data_loader) + epoch) * 1000)
            log_writer.add_scalar("loss", loss_value, epoch_1000x)
            log_writer.add_scalar('lr', warmup_lr, epoch_1000x)
            print(f"Epoch: {epoch}, Step:{data_iter_step}, Loss:{loss}, Lr:{warmup_lr}")

def build_transform(is_train, args):
    if is_train:
        #this should always dispatch to transforms_imagenet_train
        print("train transform")
        return torchvision.transforms.Compose(
            [
                torchvision.transforms.Resize((args.input_size, args.input_size)),
                torchvision.transforms.RandomHorizontalFlip(),
                torchvision.transforms.RandomVerticalFlip(),
                torchvision.transforms.RandomPerspective(distortion_scale=0.6, p = 1.0),
                torchvision.transforms.GaussianBlur(kernel_size = (5,9), sigma = (0.1, 5)),
                torchvision.transforms.ToTensor(),
            ]
        )

    # eval transofrm
    print("eval transform")
    return torchvision.transforms.Compose(
        [
            torchvision.transforms.Resize((args.input_size, args.input_size)),
            torchvision.transforms.ToTensor(),
        ]
    )



def build_dataset(is_train, args):
    transform = build_transform(is_train, args)
    path = os.path.join(args.root_path, 'train' if is_train else 'test')
    dataset = torchvision.datasets.ImageFolder(path, transform = transform)
    info = dataset.find_classes(path)
    print(f"finding classes from {path}:\t{info[0]}")
    print(f"mapping classes from {path} to indexes:\t{info[1]}")

    return dataset

def get_args_parser():
    parser = argparse.ArgumentParser('MAE pre-training', add_help=False)
    parser.add_argument('--batch_size', default=72, type=int,
                        help='Batch size per GPU (effective batch size is batch_size * accum_iter * # gpus')
    parser.add_argument('--epochs', default=400, type=int)
    parser.add_argument('--accum_iter', default=1, type=int,
                        help='Accumulate gradient iterations (for increasing the effective batch size under memory constraints)')

    # Model parameters
    parser.add_argument('--input_size', default=128, type=int,
                        help='images input size')

    # Optimizer parameters
    parser.add_argument('--weight_decay', type=float, default=0.0001,
                        help='weight decay (default: 0.0001)')

    parser.add_argument('--lr', type=float, default=0.0001, metavar='LR',
                        help='learning rate (absolute lr)')

    # Dataset parameters
    parser.add_argument('--root_path', default='dataset_fruit_veg', type=str,
                        help='dataset path')

    parser.add_argument('--output_dir', default='./output_dir_pretrained',
                        help='path where to save, empty for no saving')
    parser.add_argument('--log_dir', default='./output_dir_pretrained',
                        help='path where to tensorboard log')

    parser.add_argument('--resume', default='',
                        help='resume from checkpoint')

    parser.add_argument('--start_epoch', default=0, type=int, metavar='N',
                        help='start epoch')
    parser.add_argument('--num_workers', default=5, type=int)
    parser.add_argument('--pin_mem', action='store_true',
                        help='Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.')
    parser.add_argument('--no_pin_mem', action='store_false', dest='pin_mem')
    parser.set_defaults(pin_mem=True)

    return parser


def main(args, mode = 'train', test_image_path = ''):
    print(f"{mode} model...")
    if mode == 'train':
        #构建数据批次
        # is_train = True
        # distributed = False
        dataset_train = build_dataset(is_train = True, args = args)
        dataset_val = build_dataset(is_train = False, args = args)

        #dataloader以怎样的顺序取样本
        sampler_train = torch.utils.data.RandomSampler(dataset_train)#随机
        sampler_val = torch.utils.data.SequentialSampler(dataset_val)#有序

        data_loader_train = torch.utils.data.DataLoader(
            dataset_train, sampler = sampler_train,
            batch_size = args.batch_size,
            num_workers = args.num_workers,
            pin_memory = args.pin_mem,
            drop_last = False,
        )

        data_loader_val = torch.utils.data.DataLoader(
            dataset_val, sampler = sampler_val,
            batch_size = args.batch_size,
            # batch_size = 1
            num_workers = args.num_workers,
            pin_memory = args.pin_mem,
            drop_last = False
        )

        #构建模型，这里建议看一下timm的源码
        model = timm.create_model('resnet18', pretrained = True, num_classes = 36, drop_rate = 0.1, drop_path_rate = 0.1)#加dropout
        n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad) #对生成器遍历
        print('number of trainable params (M):%.2f' % (n_parameters/1.e6))

        criterion = torch.nn.CrossEntropyLoss()
        optimizer = torch.optim.AdamW(model.parameters(), lr = args.lr, weight_decay = args.weight_decay)#带有weight_decay的优化器0.0001
        os.makedirs(args.log_dir, exist_ok = True) #日志文件夹

        log_writer = SummaryWriter(log_dir = args.log_dir)#tensorboard中记录loss曲线的东西

        loss_scaler = NativeScaler() #mae代码继承来的，可以平滑

        #resume读入已有的模型，resume为空就不读
        misc.load_model(args = args, model_without_ddp = model, optimizer = optimizer, loss_scaler = loss_scaler)

        for epoch in range(args.start_epoch, args.epochs):
            print(f"Epoch {epoch}")
            print(f"lengrh of data_loader_train is {len(data_loader_train)}")

            if epoch % 1 == 0:
                print("Evaluating...")
                model.eval()
                test_stats = evaluate(data_loader_val, model, device)
                print(f"Accuracy of the network on the {len(dataset_val)} test images: {test_stats['acc1']:.1f}%")

                #写入tensorboard
                if log_writer is not None:
                    log_writer.add_scalar('perf/test_acc1', test_stats['acc1'], epoch)
                    log_writer.add_scalar('perf/test_acc5', test_stats['acc5'], epoch)
                    log_writer.add_scalar('perf/test_loss', test_stats['loss'], epoch)
                model.train()

            print("Training...")
            train_stats = train_one_epoch(
                model, criterion, data_loader_train,
                optimizer, device, epoch+1,
                loss_scaler, None,
                log_writer = log_writer,
                args = args
            )

            if args.output_dir:
                print("Saving checkpoints...")
                misc.save_model(
                    args = args, model = model, model_without_ddp = model, optimizer = optimizer,
                    loss_scaler = loss_scaler, epoch = epoch)


    else:
        model = timm.create_model('resnet18', pretrained = True, num_classes = 36, drop_rate = 0.1, drop_path_rate = 0.1)

        class_dict =  {'apple': 0, 'banana': 1, 'beetroot': 2, 'bell pepper': 3, 'cabbage': 4, 'capsicum': 5, 'carrot': 6, 'cauliflower': 7, 'chilli pepper': 8, 'corn': 9, 'cucumber': 10,\
             'eggplant': 11, 'garlic': 12, 'ginger': 13, 'grapes': 14, 'jalepeno': 15, 'kiwi': 16, 'lemon': 17, 'lettuce': 18, 'mango': 19, 'onion': 20, 'orange': 21, 'paprika': 22,\
                 'pear': 23, 'peas': 24, 'pineapple': 25, 'pomegranate': 26, 'potato': 27, 'raddish': 28, 'soy beans': 29, 'spinach': 30, 'sweetcorn': 31,\
                     'sweetpotato': 32, 'tomato': 33, 'turnip': 34, 'watermelon': 35}

        n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print('number of params (M):%.2f' % (n_parameters/1.e6))

        optimizer = torch.optim.AdamW(model.parameters(), lr = args.lr, weight_decay = args.weight_decay)#其实没用
        os.makedirs(args.log_dir, exist_ok = True)
        loss_scaler = NativeScaler()
        misc.load_model(args = args, model_without_ddp = model, optimizer = optimizer, loss_scaler = loss_scaler)
        model.eval()

        image = Image.open(test_image_path).convert('RGB')#传入一张图片
        image  = image.resize((args.input_size, args.input_size), Image.ANTIALIAS)
        image = torchvision.transforms.ToTensor()(image).unsqueeze(0) #变成batch

        with torch.no_grad():
            output = model(image)

        output = torch.nn.functional.softmax(output, dim = -1)
        class_idx = torch.argmax(output, dim = 1)[0]
        score = torch.max(output,dim = 1)[0][0]
        print(f"image path is{test_image_path}")
        print(f"score is {score.item()}, class id is{class_idx.item()}, class name is {list(class_dict.keys())[list(class_dict.values()).index(class_idx)]}")#从value找key
        # time.sleep(0.5)

if __name__ == '__main__':
    args = get_args_parser()
    args = args.parse_args()

    if args.output_dir:
        Path(args.output_dir).mkdir(parents = True, exist_ok = True)
    
    mode = 'train' #infer or train

    if mode =='train':
        main(args, mode = mode)
    else:
        images = glob.glob('dataset_fruit_veg/test/*/*.jpg') #改成自己的路径

        for image in images:
            print("\n")
            main(args, mode = mode, test_image_path = image)

```